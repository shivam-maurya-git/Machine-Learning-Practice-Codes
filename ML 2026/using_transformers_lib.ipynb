{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0608a442-6ebd-4454-9c4d-39d1af0e70a7",
   "metadata": {},
   "source": [
    "## Two methods to load and run model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99935717-a370-4d49-87e0-28d229d9b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827757e-d396-431a-924a-5f89224f5de3",
   "metadata": {},
   "source": [
    "### Way 1 : Using Pipeline (less control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cac734-d6d2-4e7b-9a12-20115537f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f553d4f-1694-4f61-971d-e2edccf28346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7311f39bcc9f47c09bd1db3b80d97540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c734f7-476a-400c-8356-56c98604476f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'I am a machine learning algorithm that automates and speeds up the process of answering basic questions without the need for human intervention. I can answer questions such as \"who are you?\" or \"what are you?\" and provide relevant information to help you get the answer you need. I am always available, ready to assist you anytime you need me.'}]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00cf39-66f2-4534-8cfd-12c564a3595f",
   "metadata": {},
   "source": [
    "### Way 2 : Using AutoTokenizer, AutoModelForCausalLM (more control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da18c402-d65d-4463-b7de-fd8c95664d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "370fe6bb-04b9-45a4-9947-11da978ace6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cfa5624-2205-4b40-a9bc-eee86398703d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aaf6e33f9004d85acaeda14496451b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model.\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547e1cbc-d835-42f0-aa5e-8a8f1df82136",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90621951-67f5-45ca-bdc7-dacb0a21d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts a list of dictionaries with `\"role\"` and `\"content\"` keys to a list of token\n",
    "# ids. This method is intended for use with chat models\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\", #Return PyTorch `torch.Tensor` objects\n",
    ").to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592da99a-2c1e-4483-8d04-5975319c2ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  529, 29989,  1792, 29989, 29958,    13, 22110,   526,   366, 29973,\n",
       "             2, 29871,    13, 29966, 29989,   465, 22137, 29989, 29958,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc01f1d-ed5b-4608-8db6-c8851bcbd847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a machine learning model that was trained on a vast dataset of human speech. I was created using advanced algorithms and artificial intelligence techniques to analyze and understand human speech patterns. My primary goal is to\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:])) #tensor([[101, 2023, 2003, 1037, 7953, 102]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72d173-adcb-4814-be59-6428908d8410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
